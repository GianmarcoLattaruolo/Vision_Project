{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GianmarcoLattaruolo/Vision_Project/blob/main/Classificazione_in_localizzabile_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usiamo ResNet50 per classificare le immagini in localizzabili oppure no"
      ],
      "metadata": {
        "id": "y9h03PSsOFFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# with this line we can check if we are in colab or not\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "print(\"are we in Colab?:\",in_colab)\n",
        "\n",
        "cwd = Path(os.getcwd())\n",
        "if in_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/gdrive')\n",
        "    !pip install -q condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "    os.chdir('/gdrive/MyDrive/GeoEstimation')\n",
        "    \n",
        "else:\n",
        "    #our defult wd in local should be Vision_Project\n",
        "    if str(cwd)[-14:] == 'Vision_Project':\n",
        "        os.chdir(cwd / 'GeoEstimation')\n",
        "    sys.path.append(cwd / 'GeoEstimation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qve3sn1MzJ09",
        "outputId": "ebd5cf8d-cc52-4e36-d1b8-4fbb2103affc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "are we in Colab?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "import multiprocessing as mp"
      ],
      "metadata": {
        "id": "Yp3uAoEq-WML"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3OV84r9zGDM"
      },
      "outputs": [],
      "source": [
        "dataset_test = pd.read_csv(\"/gdrive/MyDrive/GeoEstimation/resources/im2gps3k_places365_classified.csv\").dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4k dataset for the training\n",
        "dataset = pd.read_csv(\"/gdrive/MyDrive/GeoEstimation/resources/yfcc4k.csv\").dropna()\n",
        "indexNames = dataset[ dataset['LOC'] == 7 ].index\n",
        "# Delete these row indexes from dataFrame\n",
        "dataset.drop(indexNames , inplace=True)\n",
        "wrong_row = dataset[dataset['IMG_ID'] == '2902900480(1).jpg'].index\n",
        "dataset.drop(wrong_row, inplace=True)\n",
        "set(dataset['LOC'])"
      ],
      "metadata": {
        "id": "I50nfkR5YO02",
        "outputId": "37b70897-8df0-464d-8087-b4bac2870556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0, 1.0, 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_row = dataset[dataset['IMG_ID'] == '2902900480(1).jpg'].index\n",
        "dataset.drop(wrong_row, inplace=True)"
      ],
      "metadata": {
        "id": "LcApmDoLA9io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_test = [\"/gdrive/MyDrive/GeoEstimation/resources/images/im2gps3k/{}\".format(img) for img in dataset['IMG_ID']]"
      ],
      "metadata": {
        "id": "05gL7vba_C47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4k dataset for the training\n",
        "images = [\"/gdrive/MyDrive/GeoEstimation/resources/images/yfcc4k/{}\".format(img) for img in dataset['IMG_ID']]"
      ],
      "metadata": {
        "id": "3Gd8ILHAZZT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#images = [\"/gdrive/MyDrive/GeoEstimation/resources/images/im2gps3k/{}\".format(img) for img in dataset['IMG_ID']]\n",
        "#img_all = [Image.open(image) for image in images]\n",
        "#img_data = [asarray(img) for img in img_all]"
      ],
      "metadata": {
        "id": "q1prIQSh_rCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to load all the images in an array format in img_array\n",
        "# other \"easier solutions\" were really slow, this works fine\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "def load_image(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize((256, 256))\n",
        "        return np.asarray(img)\n",
        "\n",
        "# Crea una pool di processi\n",
        "with mp.Pool() as pool:\n",
        "  # Carica le immagini in parallelo\n",
        "  images = tqdm([\"/gdrive/MyDrive/GeoEstimation/resources/images/yfcc4k/{}\".format(img) for img in dataset['IMG_ID']])\n",
        "  img_data = pool.map(load_image, images)\n",
        "\n",
        "# Crea un array multidimensionale a partire dalla lista di array numpy\n",
        "img_array = np.stack(img_data)\n"
      ],
      "metadata": {
        "id": "TU6uhK1fBCvL",
        "outputId": "48a7761b-461d-4794-9c90-d4b51fd216c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4368/4368 [00:27<00:00, 161.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(fout.npy, img_array)"
      ],
      "metadata": {
        "id": "bFDNmX9rOsg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fout = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/images4k_array.npy'\n",
        "np.save(fout, img_array)"
      ],
      "metadata": {
        "id": "z0uAFvvBMcAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fout = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/images4k_array.npy'\n",
        "img_array = np.load(fout)"
      ],
      "metadata": {
        "id": "_K2N9dBjPP5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to load all the images in an array format in img_array\n",
        "# other \"easier solutions\" were really slow, this works fine\n",
        "\n",
        "# test set\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "# Crea una pool di processi\n",
        "with mp.Pool() as pool:\n",
        "  # Carica le immagini in parallelo\n",
        "  images_test = tqdm([\"/gdrive/MyDrive/GeoEstimation/resources/images/im2gps3k/{}\".format(img) for img in dataset_test['IMG_ID']])\n",
        "  img_data_test = pool.map(load_image, images_test)\n",
        "\n",
        "# Crea un array multidimensionale a partire dalla lista di array numpy\n",
        "img_array_test = np.stack(img_data_test)"
      ],
      "metadata": {
        "id": "UIu_I23D8iOl",
        "outputId": "2e4aa946-d8ad-4e6c-f2c4-32cf7da3f1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2997/2997 [03:35<00:00, 13.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fout2 = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/images_test3k_array.npy'\n",
        "np.save(fout2, img_array_test)"
      ],
      "metadata": {
        "id": "Ap5EtVHMMcmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fout2 = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/images_test3k_array.npy'\n",
        "img_array_test = np.load(fout2)"
      ],
      "metadata": {
        "id": "-daND3qaPWn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can re-set the GPU\n",
        "import tensorflow as tf\n",
        "tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU')"
      ],
      "metadata": {
        "id": "c5-5q0XnbdDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUgZOJiMB0TB",
        "outputId": "916ec39d-a78d-43d3-e77c-7a7163ae5102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4368, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_array_test.shape"
      ],
      "metadata": {
        "id": "JiLnQ8lwKgFP",
        "outputId": "367506bc-a15a-45c8-fef9-80df9e6a2b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2997, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the labels\n",
        "label_array = np.array(dataset['LOC']).reshape((img_array.shape[0], 1))\n",
        "# the labels\n",
        "label_array_test = np.array(dataset_test['LOC']).reshape((img_array_test.shape[0], 1))"
      ],
      "metadata": {
        "id": "DHU3bHimG6BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_int = label_array.astype(int)\n",
        "\n",
        "# Conto gli zeri, gli uni e i due nell'array\n",
        "count = np.bincount(labels_int.flatten())\n",
        "\n",
        "# Stampo i risultati\n",
        "print(f\"Zeri: {count[0]}\")\n",
        "print(f\"Uni: {count[1]}\")\n",
        "print(f\"Due: {count[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dYXWB-jHbdF",
        "outputId": "bfcabe5a-cfaf-490c-d69b-2ec0fcc89fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeri: 1821\n",
            "Uni: 768\n",
            "Due: 1779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(img_array, label_array, test_size=0.16, random_state=123)"
      ],
      "metadata": {
        "id": "wuVea11HH4Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = img_array\n",
        "y_train = label_array\n",
        "X_test = img_array_test\n",
        "y_test = label_array_test"
      ],
      "metadata": {
        "id": "swob5OS69Boe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processing data for one-hot encoding\n",
        "def preprocess_data(X, Y):\n",
        "  X_p = preprocess_input(X)\n",
        "  Y_p = to_categorical(Y, 3)\n",
        "  return X_p, Y_p"
      ],
      "metadata": {
        "id": "X8H8pyzrIaoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_test = enc.fit_transform(y_test).toarray()\n",
        "y_train = enc.fit_transform(y_train).toarray()"
      ],
      "metadata": {
        "id": "t01Xn_5eRU4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.where(label_array != 0, 1, 0)\n",
        "y_test = np.where(label_array_test != 0, 1, 0)"
      ],
      "metadata": {
        "id": "8bzaGKTUUy2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding applied both to train and test sets\n",
        "#X_train, y_train = preprocess_data(X_train, y_train)\n",
        "#X_test, y_test = preprocess_data(X_test, y_test)"
      ],
      "metadata": {
        "id": "flbQ9Dl7Iamj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the model\n",
        "input_t = Input(shape=(256, 256, 3))\n",
        "res_model = ResNet50(include_top=False, #resnet50\n",
        "                   weights='imagenet', #pretrained from imagenet\n",
        "                   input_tensor=input_t)"
      ],
      "metadata": {
        "id": "tIR_S__uIaeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set all the layers not-trainable\n",
        "for layer in res_model.layers[:]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "qki4H0z5IaZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add trainable layers to performe the classification\n",
        "model = Sequential()\n",
        "model.add(res_model)\n",
        "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "u9G3W37jIaXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(learning_rate=0.05),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cjmR-FuSJ00l",
        "outputId": "4fbdb1c5-e068-424a-923a-8982ea8f1a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " average_pooling2d_4 (Averag  (None, 7, 7, 2048)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 100353    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,688,065\n",
            "Trainable params: 100,353\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyyaml h5py"
      ],
      "metadata": {
        "id": "IIob72bLLPKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoints\n",
        "checkpoint_path = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "metadata": {
        "id": "sxn0GTXNI1UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoints and fit\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=8, callbacks=[cp_callback], verbose=1)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcUkjOXUI9g6",
        "outputId": "c088580f-d1ec-43b2-d8f2-df82f686aec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 66.3989 - accuracy: 0.7626\n",
            "Epoch 1: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 21s 129ms/step - loss: 66.3989 - accuracy: 0.7626\n",
            "Epoch 2/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 29.7563 - accuracy: 0.8498\n",
            "Epoch 2: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 18s 128ms/step - loss: 29.7563 - accuracy: 0.8498\n",
            "Epoch 3/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 15.4552 - accuracy: 0.9009\n",
            "Epoch 3: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 17s 125ms/step - loss: 15.4552 - accuracy: 0.9009\n",
            "Epoch 4/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 13.9395 - accuracy: 0.9041\n",
            "Epoch 4: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 17s 126ms/step - loss: 13.9395 - accuracy: 0.9041\n",
            "Epoch 5/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 6.8362 - accuracy: 0.9402\n",
            "Epoch 5: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 17s 125ms/step - loss: 6.8362 - accuracy: 0.9402\n",
            "Epoch 6/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 7.1087 - accuracy: 0.9407\n",
            "Epoch 6: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 17s 127ms/step - loss: 7.1087 - accuracy: 0.9407\n",
            "Epoch 7/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 4.1784 - accuracy: 0.9519\n",
            "Epoch 7: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 17s 127ms/step - loss: 4.1784 - accuracy: 0.9519\n",
            "Epoch 8/8\n",
            "137/137 [==============================] - ETA: 0s - loss: 4.0822 - accuracy: 0.9604\n",
            "Epoch 8: saving model to /gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/training_1/cp.ckpt\n",
            "137/137 [==============================] - 17s 126ms/step - loss: 4.0822 - accuracy: 0.9604\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " average_pooling2d_4 (Averag  (None, 7, 7, 2048)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 100353    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,688,065\n",
            "Trainable params: 100,353\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "id": "6esE75wcOfC5",
        "outputId": "2725b867-a987-4e0f-b3a0-145e521b89e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp.ckpt.data-00000-of-00001', 'cp.ckpt.index', 'checkpoint']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9nXGFQJI9cw",
        "outputId": "a8f8b84e-3a7d-42f1-d747-bb73128a1d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 12s 117ms/step - loss: 53.7093 - accuracy: 0.8208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import plot_roc_curve"
      ],
      "metadata": {
        "id": "LH_tbeZgYGtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_curve(model, X_train, y_train)"
      ],
      "metadata": {
        "id": "r4KRozSpYNta",
        "outputId": "237d8dc8-6e87-4881-e236-0f6e75071591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-e6874fb348de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_plot/roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[0;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, pos_label, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0mcheck_matplotlib_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"plot_roc_curve\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m     y_pred, pos_label = _get_response(\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_plot/base.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(X, estimator, response_method, pos_label)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprediction_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_classifier_response_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 'estimator' to be a binary classifier, but got Sequential"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test)"
      ],
      "metadata": {
        "id": "0VR4KF8FI9ak",
        "outputId": "4d619d6e-640f-4df0-e7b7-74ff2304e93f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 12s 120ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict on the 22k"
      ],
      "metadata": {
        "id": "QQ9PucnK9rwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_25k = pd.read_csv(\"/gdrive/MyDrive/GeoEstimation/resources/data25k_places365.csv\").dropna()"
      ],
      "metadata": {
        "id": "7DQnoumU9qkH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "def load_image(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize((256, 256))\n",
        "        return np.asarray(img)\n",
        "\n",
        "# Crea una pool di processi\n",
        "with mp.Pool() as pool:\n",
        "  # Carica le immagini in parallelo\n",
        "  images_25k = tqdm([\"/gdrive/MyDrive/GeoEstimation/resources/images/new_data25k/{}\".format(img) for img in dataset_25k['IMG_ID']])\n",
        "  img_data_25k = pool.map(load_image, images_25k)\n",
        "\n",
        "# Crea un array multidimensionale a partire dalla lista di array numpy\n",
        "img_array_25k = np.stack(img_data_25k)\n",
        "\n",
        "fout = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/images25k_array.npy'\n",
        "np.save(fout, img_array_25k)"
      ],
      "metadata": {
        "id": "mZSo08ZQ9qht",
        "outputId": "fe74bb9d-31b0-416c-86c6-03e99dbb6e5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22354/22354 [03:00<00:00, 123.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def load_image(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize((256, 256))\n",
        "        return np.asarray(img)\n",
        "\n",
        "# Caricamento delle immagini in batch utilizzando tf.data.Dataset\n",
        "image_paths = [\"/gdrive/MyDrive/GeoEstimation/resources/images/new_data25k/{}\".format(img) for img in dataset_25k['IMG_ID']]\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "image_dataset = image_dataset.map\n"
      ],
      "metadata": {
        "id": "o7PyYkz_ONq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fout = '/gdrive/MyDrive/GeoEstimation/checkpoints-ourResNet/images25k_array.npy'\n",
        "np.save(fout, img_array_25k)"
      ],
      "metadata": {
        "id": "qoNYT7VQ9qfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbizTfyP9qdK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}