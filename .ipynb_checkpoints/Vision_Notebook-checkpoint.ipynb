{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"4d112b5799924669bd63a025faac2662","deepnote_cell_type":"text-cell-p","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["Vision and Cognition System - Project"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The main link and paper that we need to follow is [this](https://github.com/TIBHannover/GeoEstimation)"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"229c0873cb154b66afac0ee4a74aec2c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5,"execution_start":1674041104001,"source_hash":"f553fbde","tags":[]},"outputs":[],"source":["\n","\n","url = pd.read_csv(r\"C:\\Users\\latta\\GitHub\\Vision_Project\\mp16_urls.csv\", names = [\"name\",\"url\"])\n","#read the pandas csv requires 20 sec"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Maybe we will need this [site](https://opensourceoptions.com/blog/use-python-to-download-multiple-files-or-urls-in-parallel/)\n","\n","Seguendo il paper [Where in the World is this Image? Transformer-based Geo-localization in the Wild](file:///C:/Users/latta/Downloads/Translocator_with_supplementary.pdf) tra le reference c'è il dataset del paper [Revisiting IM2GPS in the Deep Learning Era](https://arxiv.org/abs/1705.04838) che dà accesso al [sito](https://paperswithcode.com/dataset/yfcc100m) da cui si arriva in [Multimedia Commons](http://www.multimediacommons.org/). Qui comunque ci si rende conta che serve avere qualche tipo di account con i services di amazon per poter usare il dataset."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(4723695, 2)\n"]}],"source":["print(np.shape(url))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["'http://farm1.staticflickr.com/91/236416609_d7daddff3b.jpg'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'f2/52/236416609.jpg'"]},"metadata":{},"output_type":"display_data"}],"source":["display(url['url'][10])\n","display(url['name'][10])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Davide ha trovato questo che forse è meglio [kaggle](https://www.kaggle.com/code/habedi/inspect-the-dataset/data)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Qui ci sono dei links che potrebbero essere usati con colab col comando [!wget](https://qualinet.github.io/databases/image/world_wide_scale_geotagged_image_dataset_for_automatic_image_annotation_and_reverse_geotagging/)"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"e583cc450fac4fd294c8076a1fbf5ede","deepnote_persisted_session":{"createdAt":"2023-01-18T12:55:37.385Z"},"kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"}}},"nbformat":4,"nbformat_minor":0}
