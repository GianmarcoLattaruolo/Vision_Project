{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GianmarcoLattaruolo/Vision_Project/blob/main/test_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35233cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\latta\\GitHub\\Vision_Project\\GeoEstimation')\n",
    "sys.path.append(r'C:\\Users\\latta\\GitHub\\Vision_Project\\GeoEstimation')\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from classification.train_base import MultiPartitioningClassifier # class defining our model\n",
    "from classification.dataset import FiveCropImageDataset # class for preparing the images before giving them to the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3030239",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08e673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where model's params and hyperparams are saved\n",
    "checkpoint = \"models/base_M/epoch=014-val_loss=18.4833.ckpt\"\n",
    "hparams = \"models/base_M/hparams.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d442211f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'pytorch_lightning.core.lightning.LightningModule'>,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'abc.ABC'>, <class 'pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin'>, <class 'pytorch_lightning.core.grads.GradInformation'>, <class 'pytorch_lightning.core.saving.ModelIO'>, <class 'pytorch_lightning.core.hooks.ModelHooks'>, <class 'pytorch_lightning.core.hooks.DataHooks'>, <class 'pytorch_lightning.core.hooks.CheckpointHooks'>, <class 'torch.nn.modules.module.Module'>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'object'>,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_MultiPartitioningClassifier__build_model',\n",
       " '_MultiPartitioningClassifier__init_partitionings',\n",
       " '_multi_crop_inference',\n",
       " 'inference'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this cell is just to explore the number of attributes of the classes we have to work with\n",
    "methods_MultiPar = [method_name for method_name in dir(MultiPartitioningClassifier)\n",
    "                  if callable(getattr(MultiPartitioningClassifier, method_name))]\n",
    "display(len(methods_MultiPar))\n",
    "\n",
    "#MultiPartioningClassifier is child of pl.LightningModule\n",
    "print(MultiPartitioningClassifier.__bases__)\n",
    "methods_pl_Ligh = [method_name for method_name in dir(pl.LightningModule)\n",
    "                  if callable(getattr(pl.LightningModule, method_name))]\n",
    "display(len(methods_pl_Ligh))\n",
    "\n",
    "#pl.LightningModule is child of torch.nn.modules.module.Module and several other PyTorch lightning classes\n",
    "print(pl.LightningModule.__bases__)\n",
    "methods_pytorch_nn = [method_name for method_name in dir(torch.nn.modules.module.Module)\n",
    "                  if callable(getattr(torch.nn.modules.module.Module, method_name))]\n",
    "display(len(methods_pytorch_nn))\n",
    "\n",
    "#torch.nn.modules.module.Module is not a child class\n",
    "print(torch.nn.modules.module.Module.__bases__)\n",
    "\n",
    "#only 4 attributes/methods from MultiPartitioningClassifier are new w.r.t. pl.LightningModule\n",
    "#but I guess some are overwritten\n",
    "display(set(methods_MultiPar)-set(methods_pl_Ligh)) \n",
    "display(set(methods_pl_Ligh)-set(methods_MultiPar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34a91b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "INFO:lightning:GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# load_from_checkpoint is a static method from pytorch lightning, inherited by MultiPartitioningClassifier\n",
    "# it permits to load a model previously saved, in the form of a checkpoint file, and one with hyperparameters\n",
    "# MultiPartitioningClassifier is the class defining our model\n",
    "model = MultiPartitioningClassifier.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint,\n",
    "    hparams_file=hparams,\n",
    "    map_location=None,\n",
    "    stric = False #Whether to strictly enforce that the keys in checkpoint_path match\n",
    "    # the keys returned by this module’s state dict.\n",
    ")\n",
    "#I put some the function's variables from the documentation, with some comments\n",
    "wanted_precision = 32\n",
    "trainer = pl.Trainer(callbacks=None, #Add a callback or list of callbacks.\n",
    "                     gradient_clip_val=None, #The value at which to clip gradients. Passing gradient_clip_val=None disables gradient clipping\n",
    "                     track_grad_norm= -1, #-1 = no track, otherwise tracks the p-norm. May be set to ‘inf’ infinity-norm. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before logging them. \n",
    "                     check_val_every_n_epoch=1, # Perform a validation loop every after every N training epochs.\n",
    "                     max_epochs=None, # Stop training once this number of epochs is reached. Disabled by default (None). If both max_epochs and max_steps are not specified, defaults to max_epochs = 1000. To enable infinite training, set max_epochs = -1.\n",
    "                     max_steps = -1, #Stop training after this number of steps. \n",
    "                     log_every_n_steps=50, #How often to log within steps. Default: 50\n",
    "                     accelerator=None, # different accelerator types (“cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”)\n",
    "                     precision=wanted_precision, #Double precision (64), full precision (32), half precision (16) or bfloat16 precision (bf16).\n",
    "                     resume_from_checkpoint=None, #Deprecated since version v1.5:use Trainer.fit(..., ckpt_path=...) instead.\n",
    "                     auto_lr_find=False, #If set to True, will make trainer.tune() run a learning rate finder, trying to optimize initial learning for faster convergence.\n",
    "                     auto_scale_batch_size=False) #If set to True, will initially run a batch size finder trying to find the largest batch size that fits into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bc50a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read resources\\images\\im2gps3k_places365.csv\n"
     ]
    }
   ],
   "source": [
    "# I want to train on the second 3k-images test set\n",
    "image_dir = r\"resources\\images\\im2gps3ktest\"\n",
    "meta_csv = r\"resources\\images\\im2gps3k_places365.csv\"\n",
    "#FiveCropImageDataset is the class for preparing the images before giving them to the NN\n",
    "# in particular, it creates five different crops for every image\n",
    "dataset = FiveCropImageDataset(meta_csv, image_dir)\n",
    "batch_size = 64\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=ceil(batch_size / 5),  #you divide by 5 because for each image you generate 5 different crops\n",
    "                    shuffle=False,\n",
    "                    num_workers=4 #number ot threads used for parallelism (cores of CPU?)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d6ed7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | model      | Sequential | 23 M  \n",
      "1 | classifier | ModuleList | 47 M  \n",
      "INFO:lightning:\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | model      | Sequential | 23 M  \n",
      "1 | classifier | ModuleList | 47 M  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resources/yfcc_25600_places365_mapping_h3.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#we need to specify the validation data since we don't have the file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m new_training \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit(model \u001b[39m=\u001b[39;49m model, \u001b[39m#model to  fit\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m                            train_dataloader\u001b[39m=\u001b[39;49mdataloader, \u001b[39m# Pytorch DataLoader with training samples. \u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m                            \u001b[39m#If the model has a predefined train_dataloader method this will be skipped \u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m                            val_dataloaders\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \u001b[39m#Either a single Pytorch Dataloader or a list of them, \u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m                            \u001b[39m# specifying validation samples. If the model has a predefined val_dataloaders \u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m                            \u001b[39m# method this will be skipped\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m                            datamodule\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:440\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m# TRAIN\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 440\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator_backend\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator_backend\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m    443\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\accelerators\\cpu_accelerator.py:48\u001b[0m, in \u001b[0;36mCPUAccelerator.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtrain_loop\u001b[39m.\u001b[39msetup_training(model)\n\u001b[0;32m     47\u001b[0m \u001b[39m# train or test\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_or_test()\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:66\u001b[0m, in \u001b[0;36mAccelerator.train_or_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mrun_test()\n\u001b[0;32m     65\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:462\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 462\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_sanity_check(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_model())\n\u001b[0;32m    464\u001b[0m     \u001b[39m# enable train mode\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:638\u001b[0m, in \u001b[0;36mTrainer.run_sanity_check\u001b[1;34m(self, ref_model)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39m# run tiny validation (if validation defined)\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[39m# to make sure program won't crash during val\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39mif\u001b[39;00m should_sanity_check:\n\u001b[1;32m--> 638\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_val_dataloader(ref_model)\n\u001b[0;32m    639\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_sanity_val_batches \u001b[39m=\u001b[39m [\n\u001b[0;32m    640\u001b[0m         \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_sanity_val_steps, val_batches) \u001b[39mfor\u001b[39;00m val_batches \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_val_batches\n\u001b[0;32m    641\u001b[0m     ]\n\u001b[0;32m    643\u001b[0m     \u001b[39m# hook and callback\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:316\u001b[0m, in \u001b[0;36mTrainerDataLoadingMixin.reset_val_dataloader\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    314\u001b[0m has_step \u001b[39m=\u001b[39m is_overridden(\u001b[39m'\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m'\u001b[39m, model)\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m has_loader \u001b[39mand\u001b[39;00m has_step:\n\u001b[1;32m--> 316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_val_batches, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_dataloaders \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset_eval_dataloader(model, \u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:236\u001b[0m, in \u001b[0;36mTrainerDataLoadingMixin._reset_eval_dataloader\u001b[1;34m(self, model, mode)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39m# always get the loaders first so we can count how many there are\u001b[39;00m\n\u001b[0;32m    235\u001b[0m loader_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m_dataloader\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 236\u001b[0m dataloaders \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_dataloader(\u001b[39mgetattr\u001b[39;49m(model, loader_name))\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dataloaders, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    239\u001b[0m     dataloaders \u001b[39m=\u001b[39m [dataloaders]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:339\u001b[0m, in \u001b[0;36mTrainerDataLoadingMixin.request_dataloader\u001b[1;34m(self, dataloader_fx)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest_dataloader\u001b[39m(\u001b[39mself\u001b[39m, dataloader_fx: Callable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataLoader:\n\u001b[0;32m    331\u001b[0m     \u001b[39m\"\"\"Handles downloading data in the GPU or TPU case.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39m        The dataloader\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     dataloader \u001b[39m=\u001b[39m dataloader_fx()\n\u001b[0;32m    340\u001b[0m     dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_dl_only(dataloader)\n\u001b[0;32m    342\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\GitHub\\Vision_Project\\GeoEstimation\\classification\\train_base.py:351\u001b[0m, in \u001b[0;36mMultiPartitioningClassifier.val_dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mval_dataloader\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 351\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhparams\u001b[39m.\u001b[39;49mval_label_mapping, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    352\u001b[0m         target_mapping \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m    354\u001b[0m     tfm \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mCompose(\n\u001b[0;32m    355\u001b[0m         [\n\u001b[0;32m    356\u001b[0m             torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mResize(\u001b[39m256\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m         ]\n\u001b[0;32m    363\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/yfcc_25600_places365_mapping_h3.json'"
     ]
    }
   ],
   "source": [
    "#we need to specify the validation data since we don't have the file:\n",
    "#'resources/yfcc_25600_places365_mapping_h3.json'\n",
    "\n",
    "new_training = trainer.fit(model = model, #model to  fit\n",
    "                           train_dataloader=dataloader, # Pytorch DataLoader with training samples. \n",
    "                           #If the model has a predefined train_dataloader method this will be skipped \n",
    "                           val_dataloaders=None, #Either a single Pytorch Dataloader or a list of them, \n",
    "                           # specifying validation samples. If the model has a predefined val_dataloaders \n",
    "                           # method this will be skipped\n",
    "                           datamodule=None)#A instance of LightningDataModule, optional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eab34b0a",
   "metadata": {},
   "source": [
    "# Some useful links\n",
    "\n",
    "[load_from_checkpoints](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.core.saving.ModelIO.html)\n",
    "\n",
    "[pytorch.Trainer](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html)\n",
    "\n",
    "[transfer learning](https://pytorch-lightning.readthedocs.io/en/stable/advanced/finetuning.html)\n",
    "\n",
    "[pytorch lightning 1.0.1 full documentation](https://pytorch-lightning.readthedocs.io/_/downloads/en/1.0.1/pdf/)\n",
    "unfornatuly we need to watch this since several functions arguments have changed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fa9b9afc2baba5ccea1aafc34033c1dd8dcf2295c2dc2a369baeb32b0f17743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
