{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d112b5799924669bd63a025faac2662",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Vision and Cognition Systems - Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#libraries to import\n",
    "#known\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import torchvision\n",
    "import torch\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import sys\n",
    "import time\n",
    "\n",
    "#Unknown\n",
    "from typing import Union\n",
    "#from io import BytesIO\n",
    "import random\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import requests\n",
    "import logging\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is from ```msgpack_viewer.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MsgPackIterableDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        key_img_id: str = \"id\",\n",
    "        key_img_encoded: str = \"image\",\n",
    "        transformation=None,\n",
    "        shuffle=False,\n",
    "        cache_size=6 * 4096,\n",
    "    ):\n",
    "\n",
    "        super(MsgPackIterableDataset, self).__init__()\n",
    "        self.path = path\n",
    "        self.cache_size = cache_size\n",
    "        self.transformation = transformation\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = random.randint(1, 100)\n",
    "        self.key_img_id = key_img_id.encode(\"utf-8\")\n",
    "        self.key_img_encoded = key_img_encoded.encode(\"utf-8\")\n",
    "\n",
    "        if not isinstance(self.path, (list, set)):\n",
    "            self.path = [self.path]\n",
    "        \n",
    "        self.shards = self.__init_shards(self.path)\n",
    "\n",
    "    @staticmethod\n",
    "    def __init_shards(path: Union[str, Path]) -> list:\n",
    "        shards = []\n",
    "        for i, p in enumerate(path):\n",
    "            shards_re = r\"shard_(\\d+).msg\"\n",
    "            shards_index = [\n",
    "                int(re.match(shards_re, x).group(1))\n",
    "                for x in os.listdir(p)\n",
    "                if re.match(shards_re, x)\n",
    "            ]\n",
    "            shards.extend(\n",
    "                [\n",
    "                    {\n",
    "                        \"path_index\": i,\n",
    "                        \"path\": p,\n",
    "                        \"shard_index\": s,\n",
    "                        \"shard_path\": os.path.join(p, f\"shard_{s}.msg\"),\n",
    "                    }\n",
    "                    for s in shards_index\n",
    "                ]\n",
    "            )\n",
    "        if len(shards) == 0:\n",
    "            raise ValueError(\"No shards found\")\n",
    "        \n",
    "        return shards\n",
    "\n",
    "    def _process_sample(self, x):\n",
    "        # decode and initial resize if necessary\n",
    "        img = Image.open(BytesIO(x[self.key_img_encoded]))\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "        if img.width > 320 and img.height > 320:\n",
    "            img = torchvision.transforms.Resize(320)(img)\n",
    "\n",
    "        # apply all user specified image transformations\n",
    "        if self.transformation is not None:\n",
    "            img = self.transformation(img)\n",
    "        \n",
    "        _id = x[self.key_img_id].decode(\"utf-8\")\n",
    "        return img, _id\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        shard_indices = list(range(len(self.shards)))\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.seed(self.seed)\n",
    "            random.shuffle(shard_indices)\n",
    "\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "\n",
    "        if worker_info is not None:\n",
    "\n",
    "            def split_list(alist, splits=1):\n",
    "                length = len(alist)\n",
    "                return [\n",
    "                    alist[i * length // splits : (i + 1) * length // splits]\n",
    "                    for i in range(splits)\n",
    "                ]\n",
    "\n",
    "            shard_indices_split = split_list(shard_indices, worker_info.num_workers)[\n",
    "                worker_info.id\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            shard_indices_split = shard_indices\n",
    "\n",
    "        cache = []\n",
    "\n",
    "        for shard_index in shard_indices_split:\n",
    "            shard = self.shards[shard_index]\n",
    "\n",
    "            with open(\n",
    "                os.path.join(shard[\"path\"], f\"shard_{shard['shard_index']}.msg\"), \"rb\"\n",
    "            ) as f:\n",
    "                unpacker = msgpack.Unpacker(\n",
    "                    f, max_buffer_size=1024 * 1024 * 1024, raw=True\n",
    "                )\n",
    "                for x in unpacker:\n",
    "                    if x is None:\n",
    "                        continue\n",
    "\n",
    "                    if len(cache) < self.cache_size:\n",
    "                        cache.append(x)\n",
    "\n",
    "                    if len(cache) == self.cache_size:\n",
    "\n",
    "                        if self.shuffle:\n",
    "                            random.shuffle(cache)\n",
    "                        while cache:\n",
    "                            yield self._process_sample(cache.pop())\n",
    "        if self.shuffle:\n",
    "            random.shuffle(cache)\n",
    "\n",
    "        while cache:\n",
    "            yield self._process_sample(cache.pop())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    args = argparse.ArgumentParser()\n",
    "    args.add_argument(\"--data\", type=str, default=\"resources/images/mp16\")\n",
    "    args = args.parse_args()\n",
    "\n",
    "    tfm = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = MsgPackIterableDataset(path=args.data, transformation=tfm)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=6,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "    num_images = 0\n",
    "    for x, image_id in dataloader:\n",
    "        if num_images == 0:\n",
    "            print(x.shape, image_id)\n",
    "        num_images +=1\n",
    "    \n",
    "    print(f\"{num_images=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is from ```filter_by_downloaded_images.py``` that maybe we won't need since we will use a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    for dataset_type in [\"train\", \"val\"]:\n",
    "        with open(config[f\"{dataset_type}_label_mapping\"]) as f:\n",
    "            mapping = json.load(f)\n",
    "\n",
    "        logging.info(f\"Expected dataset size: {len(mapping)}\")\n",
    "        msgpack_path = config[f\"msgpack_{dataset_type}_dir\"]\n",
    "        image_ids_path = config[f\"{dataset_type}_meta_path\"]\n",
    "        dataset = MsgPackIterableMetaDataset(\n",
    "            msgpack_path,\n",
    "            image_ids_path,\n",
    "            image_ids_path,\n",
    "            key_img_id=config[\"key_img_id\"],\n",
    "            key_img_encoded=config[\"key_img_encoded\"],\n",
    "            ignore_image=True,\n",
    "        )\n",
    "\n",
    "        filtered_mapping = {}\n",
    "        for _, meta in dataset:\n",
    "            if meta[\"img_id\"] in mapping:\n",
    "                filtered_mapping[meta[\"img_id\"]] = mapping[meta[\"img_id\"]]\n",
    "        logging.info(f\"True dataset size: {len(filtered_mapping)}\")\n",
    "\n",
    "        with open(config[f\"{dataset_type}_label_mapping\"], \"w\") as fw:\n",
    "            json.dump(filtered_mapping, fw)\n",
    "    return\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"-c\", \"--config\", type=Path, default=\"config/baseM.yml\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "        datefmt=\"%d-%m-%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "\n",
    "    args = parse_args()\n",
    "\n",
    "    with open(args.config) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    config = config[\"model_params\"]\n",
    "\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally this is from ```download_images.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "class MsgPackWriter:\n",
    "    def __init__(self, path, chunk_size=4096):\n",
    "        self.path = Path(path).absolute()\n",
    "        self.path.mkdir(parents=True, exist_ok=True)\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        shards_re = r\"shard_(\\d+).msg\"\n",
    "        self.shards_index = [\n",
    "            int(re.match(shards_re, x).group(1))\n",
    "            for x in self.path.iterdir()\n",
    "            if x.is_dir() and re.match(shards_re, x)\n",
    "        ]\n",
    "        self.shard_open = None\n",
    "\n",
    "    def open_next(self):\n",
    "        if len(self.shards_index) == 0:\n",
    "            next_index = 0\n",
    "        else:\n",
    "            next_index = sorted(self.shards_index)[-1] + 1\n",
    "        self.shards_index.append(next_index)\n",
    "\n",
    "        if self.shard_open is not None and not self.shard_open.closed:\n",
    "            self.shard_open.close()\n",
    "\n",
    "        self.count = 0\n",
    "        self.shard_open = open(self.path / f\"shard_{next_index}.msg\", \"wb\")\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.open_next()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb):\n",
    "        self.shard_open.close()\n",
    "\n",
    "    def write(self, data):\n",
    "        if self.count >= self.chunk_size:\n",
    "            self.open_next()\n",
    "\n",
    "        self.shard_open.write(msgpack.packb(data))\n",
    "        self.count += 1\n",
    "\n",
    "\n",
    "def _thumbnail(img: PIL.Image, size: int) -> PIL.Image:\n",
    "    # resize an image maintaining the aspect ratio\n",
    "    # the smaller edge of the image will be matched to 'size'\n",
    "    w, h = img.size\n",
    "    if (w <= size) or (h <= size):\n",
    "        return img\n",
    "    if w < h:\n",
    "        ow = size\n",
    "        oh = int(size * h / w)\n",
    "        return img.resize((ow, oh), PIL.Image.BILINEAR)\n",
    "    else:\n",
    "        oh = size\n",
    "        ow = int(size * w / h)\n",
    "        return img.resize((ow, oh), PIL.Image.BILINEAR)\n",
    "\n",
    "\n",
    "def flickr_download(x, size_suffix=\"z\", min_edge_size=None):\n",
    "\n",
    "    # prevent downloading in full resolution using size_suffix\n",
    "    # https://www.flickr.com/services/api/misc.urls.html\n",
    "\n",
    "    image_id = x[\"image_id\"]\n",
    "    url_original = x[\"url\"]\n",
    "    if size_suffix != \"\":\n",
    "        url = url_original\n",
    "        # modify url to download image with specific size\n",
    "        ext = Path(url).suffix\n",
    "        url = f\"{url.split(ext)[0]}_{size_suffix}{ext}\"\n",
    "    else:\n",
    "        url = url_original\n",
    "\n",
    "    r = requests.get(url)\n",
    "    if r:\n",
    "        try:\n",
    "            image = PIL.Image.open(BytesIO(r.content))\n",
    "        except PIL.UnidentifiedImageError as e:\n",
    "            logger.error(f\"{image_id} : {url}: {e}\")\n",
    "            return\n",
    "    elif r.status_code == 129:\n",
    "        time.sleep(60)\n",
    "        logger.warning(\"To many requests, sleep for 60s...\")\n",
    "        flickr_download(x, min_edge_size=min_edge_size, size_suffix=size_suffix)\n",
    "    else:\n",
    "        logger.error(f\"{image_id} : {url}: {r.status_code}\")\n",
    "        return None\n",
    "\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    # resize if necessary\n",
    "    image = _thumbnail(image, min_edge_size)\n",
    "    # convert to jpeg\n",
    "    fp = BytesIO()\n",
    "    image.save(fp, \"JPEG\")\n",
    "\n",
    "    raw_bytes = fp.getvalue()\n",
    "    return {\"image\": raw_bytes, \"id\": image_id}\n",
    "\n",
    "\n",
    "class ImageDataloader:\n",
    "    def __init__(self, url_csv: Path, shuffle=False, nrows=None):\n",
    "\n",
    "        logger.info(\"Read dataset\")\n",
    "        self.df = pd.read_csv(\n",
    "            url_csv, names=[\"image_id\", \"url\"], header=None, nrows=nrows\n",
    "        )\n",
    "        # remove rows without url\n",
    "        self.df = self.df.dropna()\n",
    "        if shuffle:\n",
    "            logger.info(\"Shuffle images\")\n",
    "            self.df = self.df.sample(frac=1, random_state=10)\n",
    "        logger.info(f\"Number of URLs: {len(self.df.index)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for image_id, url in zip(self.df[\"image_id\"].values, self.df[\"url\"].values):\n",
    "            yield {\"image_id\": image_id, \"url\": url}\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    args = ArgumentParser()\n",
    "    args.add_argument(\n",
    "        \"--threads\",\n",
    "        type=int,\n",
    "        default=24,\n",
    "        help=\"Number of threads to download and process images\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--output\",\n",
    "        type=Path,\n",
    "        default=Path(\"resources/images/mp16\"),\n",
    "        help=\"Output directory where images are stored\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--url_csv\",\n",
    "        type=Path,\n",
    "        default=Path(\"resources/mp16_urls.csv\"),\n",
    "        help=\"CSV with Flickr image id and URL for downloading\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--size\",\n",
    "        type=int,\n",
    "        default=320,\n",
    "        help=\"Rescale image to a minimum edge size of SIZE\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--size_suffix\",\n",
    "        type=str,\n",
    "        default=\"z\",\n",
    "        help=\"Image size suffix according to the Flickr API; Empty string for original image\",\n",
    "    )\n",
    "    args.add_argument(\"--nrows\", type=int)\n",
    "    args.add_argument(\n",
    "        \"--shuffle\", action=\"store_true\", help=\"Shuffle list of URLs before downloading\"\n",
    "    )\n",
    "    return args.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    image_loader = ImageDataloader(args.url_csv, nrows=args.nrows, shuffle=args.shuffle)\n",
    "\n",
    "    counter_successful = 0\n",
    "    with Pool(args.threads) as p:\n",
    "        with MsgPackWriter(args.output) as f:\n",
    "            start = time.time()\n",
    "            for i, x in enumerate(\n",
    "                p.imap(\n",
    "                    partial(\n",
    "                        flickr_download,\n",
    "                        size_suffix=args.size_suffix,\n",
    "                        min_edge_size=args.size,\n",
    "                    ),\n",
    "                    image_loader,\n",
    "                )\n",
    "            ):\n",
    "                if x is None:\n",
    "                    continue\n",
    "\n",
    "                f.write(x)\n",
    "                counter_successful += 1\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    end = time.time()\n",
    "                    logger.info(f\"{i}: {1000 / (end - start):.2f} image/s\")\n",
    "                    start = end\n",
    "    logger.info(\n",
    "        f\"Sucesfully downloaded {counter_successful}/{len(image_loader)} images ({counter_successful / len(image_loader):.3f})\"\n",
    "    )\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    args.output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger = logging.getLogger(\"ImageDownloader\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    fh = logging.FileHandler(str(args.output / \"writer.log\"))\n",
    "    fh.setLevel(logging.INFO)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    sys.exit(main())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now following the github page we need:\n",
    "- item 1\n",
    "- item 2\n",
    "- item 3\n",
    "- item 4 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main link and paper that we need to follow is [this](https://github.com/TIBHannover/GeoEstimation) and [this](https://github.com/TIBHannover/GeoEstimation/releases/) for the pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davide ha trovato questo che forse è meglio [kaggle](https://www.kaggle.com/code/habedi/inspect-the-dataset/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui ci sono dei links che potrebbero essere usati con colab col comando [!wget](https://qualinet.github.io/databases/image/world_wide_scale_geotagged_image_dataset_for_automatic_image_annotation_and_reverse_geotagging/)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e583cc450fac4fd294c8076a1fbf5ede",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-18T12:55:37.385Z"
  },
  "kernelspec": {
   "display_name": "vs-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fa9b9afc2baba5ccea1aafc34033c1dd8dcf2295c2dc2a369baeb32b0f17743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
