{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vision and Cognitive Systems - Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GianmarcoLattaruolo/Vision_Project/blob/main/Vision_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmXSsJJKniqF"
      },
      "source": [
        "First of all let'smount our vision drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with this line we can check if we are in colab or not\n",
        "import sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "print(\"are we in Colab?:\",in_colab)\n",
        "if in_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import os\n",
        "    os.chdir(r'/content/drive/MyDrive/GeoEstimation')\n",
        "    print(os.getcwd())\n",
        "    !python --version\n",
        "    !pip install pandas==1.1.5\n",
        "    !pip install msgpack==1.0.0\n",
        "    !pip install tqdm==4.50\n",
        "    !pip install torch==1.6\n",
        "    !pip install torchvision==0.7\n",
        "    !pip install torchtext==0.8.0 torch==1.6 pytorch-lightning==1.0.1 \n",
        "    !pip install s2sphere==0.2.5\n",
        "\n",
        "    #we lack only this to packages\n",
        "    #!pip install yaml==0.2.5\n",
        "    #!pip install cudatoolkit==10.2\n",
        "else:\n",
        "    import os\n",
        "    current_wd = os.getcwd()\n",
        "    if current_wd.split('\\\\')[-1] == 'Vision_Project':\n",
        "        os.chdir(r'GeoEstimation')\n",
        "    sys.path.append(current_wd + r'\\GeoEstimation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSyJGMw23UYv"
      },
      "source": [
        "Now we need to install some specific packages with certain version to account for the original environment in which the paper results were obtained. We need to match these conditions:\n",
        "```python\n",
        "  - python=3.8\n",
        "  - msgpack-python=1.0.0\n",
        "  - pandas=1.1.5\n",
        "  - yaml=0.2.5\n",
        "  - tqdm=4.50\n",
        "  - cudatoolkit=10.2\n",
        "  - pytorch=1.6\n",
        "  - torchvision=0.7\n",
        "  - pytorch-lightning=1.0.1\n",
        "  - pip\n",
        "  - pip:\n",
        "    - s2sphere==0.2.5\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlQ-rzybhcR1",
        "outputId": "a0f5f676-4b49-42fa-f6fd-a99df303c29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas: 1.1.5\n",
            "yaml: 6.0\n",
            "tqdm: 4.64.1\n",
            "pytorch: 1.13.1+cu116\n",
            "torchvision: 0.7.0\n",
            "pytorch_lightning: 1.0.1\n"
          ]
        }
      ],
      "source": [
        "if in_colab:\n",
        "    import msgpack\n",
        "    #print(\"msgpack:\", msgpack.__version__) #msgpack sembra non avere l'attributo __version__ nella versiona in cui lo abbiamo installato\n",
        "    import pandas\n",
        "    print(\"pandas:\",pandas.__version__)\n",
        "    import yaml\n",
        "    print(\"yaml:\",yaml.__version__)\n",
        "    import tqdm\n",
        "    print(\"tqdm:\",tqdm.__version__)\n",
        "    #import cudatoolkit\n",
        "    #print(\"cudatoolkit:\",cudatoolkit.__version__)\n",
        "    import torch\n",
        "    print(\"pytorch:\",torch.__version__)\n",
        "    import torchvision\n",
        "    print(\"torchvision:\",torchvision.__version__)\n",
        "    import pytorch_lightning as pl\n",
        "    print(\"pytorch_lightning:\",pl.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4BF4QseoP35"
      },
      "source": [
        "# Reproduce paper results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from math import ceil\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from classification.train_base import MultiPartitioningClassifier # class defining our model\n",
        "from classification.dataset import FiveCropImageDataset # class for preparing the images before giving them to the NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# where model's params and hyperparams are saved\n",
        "checkpoint = \"models/base_M/epoch=014-val_loss=18.4833.ckpt\"\n",
        "hparams = \"models/base_M/hparams.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\latta/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:29<00:00, 3.48MB/s]\n"
          ]
        }
      ],
      "source": [
        "# load_from_checkpoint is a static method from pytorch lightning, inherited by MultiPartitioningClassifier\n",
        "# it permits to load a model previously saved, in the form of a checkpoint file, and one with hyperparameters\n",
        "# MultiPartitioningClassifier is the class defining our model\n",
        "model = MultiPartitioningClassifier.load_from_checkpoint(\n",
        "    checkpoint_path=checkpoint,\n",
        "    hparams_file=hparams,\n",
        "    map_location=None\n",
        ")\n",
        "\n",
        "#model.eval() to see the model's structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "INFO:lightning:GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ],
      "source": [
        "#to allow GPU\n",
        "want_gpu = True\n",
        "if want_gpu and torch.cuda.is_available():\n",
        "    gpu = 1\n",
        "else:\n",
        "    gpu = None\n",
        "\n",
        "# the class Trainer from pythorch lightining is the one responsible for training a deep NN\n",
        "# it can initialize the model, run forward and backward passes, optimize, print stats, early stop...\n",
        "wanted_precision = 32 #16 for half precision (how many bits for each number)\n",
        "trainer = pl.Trainer(gpus=gpu, precision=wanted_precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and initialize the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# where images are saved\n",
        "image_dir = \"resources/images/im2gps\"\n",
        "meta_csv = \"resources/images/im2gps_places365.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read resources/images/im2gps_places365.csv\n"
          ]
        }
      ],
      "source": [
        "#FiveCropImageDataset is the class for preparing the images before giving them to the NN\n",
        "# in particular, it creates five different crops for every image\n",
        "dataset = FiveCropImageDataset(meta_csv, image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "                    dataset,\n",
        "                    batch_size=ceil(batch_size / 5),  #you divide by 5 because for each image you generate 5 different crops\n",
        "                    shuffle=False,\n",
        "                    num_workers=4 #number ot threads used for parallelism (cores of CPU?)\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 19/19 [05:05<00:00, 16.07s/it]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:45: UserWarning: The testing_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "results = trainer.test(model, test_dataloaders=dataloader, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Look at the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  1         25        200       750       2500\n",
            "partitioning                                                  \n",
            "coarse        0.092827  0.312236  0.493671  0.666667  0.789030\n",
            "middle        0.139241  0.345992  0.481013  0.679325  0.789030\n",
            "fine          0.156118  0.388186  0.489451  0.662447  0.784810\n",
            "hierarchy     0.147679  0.379747  0.497890  0.687764  0.793249\n"
          ]
        }
      ],
      "source": [
        "# formatting results into a pandas dataframe\n",
        "df = pd.DataFrame(results[0]).T\n",
        "#df[\"dataset\"] = image_dir\n",
        "df[\"partitioning\"] = df.index\n",
        "df[\"partitioning\"] = df[\"partitioning\"].apply(lambda x: x.split(\"/\")[-1])\n",
        "df.set_index(keys=[\"partitioning\"], inplace=True) #keys=[\"dataset\", \"partitioning\"] in case\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to save the dataframe on a csv file\n",
        "fout = 'test_results.csv'\n",
        "df.to_csv(fout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tboo2F-YxCDS"
      },
      "source": [
        "This two commands give the same error:\n",
        "```python\n",
        "OSError: /usr/local/lib/python3.8/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c104impl23ExcludeDispatchKeyGuardC1ENS_14DispatchKeySetE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Kt1rQBt4rujf",
        "outputId": "a69c0905-84ae-4546-fbca-d30d758a5c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/MyDrive/GeoEstimation/classification/inference.py\", line 8, in <module>\n",
            "    from classification.train_base import MultiPartitioningClassifier\n",
            "  File \"/content/drive/MyDrive/GeoEstimation/classification/train_base.py\", line 10, in <module>\n",
            "    import pytorch_lightning as pl\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/__init__.py\", line 56, in <module>\n",
            "    from pytorch_lightning.core import LightningDataModule, LightningModule\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/__init__.py\", line 14, in <module>\n",
            "    from pytorch_lightning.core.datamodule import LightningDataModule\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/datamodule.py\", line 22, in <module>\n",
            "    from pytorch_lightning.core.hooks import CheckpointHooks, DataHooks\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/hooks.py\", line 18, in <module>\n",
            "    from pytorch_lightning.utilities import AMPType, move_data_to_device, rank_zero_warn\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/__init__.py\", line 20, in <module>\n",
            "    from pytorch_lightning.utilities.apply_func import move_data_to_device\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 25, in <module>\n",
            "    from torchtext.data import Batch\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchtext/__init__.py\", line 40, in <module>\n",
            "    _init_extension()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchtext/__init__.py\", line 36, in _init_extension\n",
            "    torch.ops.load_library(ext_specs.origin)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_ops.py\", line 105, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /usr/local/lib/python3.8/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c104impl23ExcludeDispatchKeyGuardC1ENS_14DispatchKeySetE\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/MyDrive/GeoEstimation/classification/test.py\", line 6, in <module>\n",
            "    import pytorch_lightning as pl\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/__init__.py\", line 56, in <module>\n",
            "    from pytorch_lightning.core import LightningDataModule, LightningModule\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/__init__.py\", line 14, in <module>\n",
            "    from pytorch_lightning.core.datamodule import LightningDataModule\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/datamodule.py\", line 22, in <module>\n",
            "    from pytorch_lightning.core.hooks import CheckpointHooks, DataHooks\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/hooks.py\", line 18, in <module>\n",
            "    from pytorch_lightning.utilities import AMPType, move_data_to_device, rank_zero_warn\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/__init__.py\", line 20, in <module>\n",
            "    from pytorch_lightning.utilities.apply_func import move_data_to_device\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 25, in <module>\n",
            "    from torchtext.data import Batch\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchtext/__init__.py\", line 40, in <module>\n",
            "    _init_extension()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchtext/__init__.py\", line 36, in _init_extension\n",
            "    torch.ops.load_library(ext_specs.origin)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_ops.py\", line 105, in load_library\n",
            "    ctypes.CDLL(path)\n",
            "  File \"/usr/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /usr/local/lib/python3.8/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c104impl23ExcludeDispatchKeyGuardC1ENS_14DispatchKeySetE\n"
          ]
        }
      ],
      "source": [
        "#Inference with pre-trained model:\n",
        "!python3 -m classification.inference --image_dir resources/images/im2gps/\n",
        "print(\"\\n\\n\\n\")\n",
        "#Test on Already Trained Model\n",
        "!python -m classification.test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTG72pB0x3tT"
      },
      "source": [
        "These are the other commands for Training from Scratch (that we won't use maybe):\n",
        "\n",
        "```python\n",
        "# download and preprocess images\n",
        "wget https://github.com/TIBHannover/GeoEstimation/releases/download/v1.0/mp16_urls.csv -O resources/mp16_urls.csv\n",
        "wget https://github.com/TIBHannover/GeoEstimation/releases/download/pytorch/yfcc25600_urls.csv -O resources/yfcc25600_urls.csv \n",
        "python download_images.py --output resources/images/mp16 --url_csv resources/mp16_urls.csv --shuffle\n",
        "python download_images.py --output resources/images/yfcc25600 --url_csv resources/yfcc25600_urls.csv --shuffle --size_suffix \"\"\n",
        "\n",
        "# assign cell(s) for each image using the original meta information\n",
        "wget https://github.com/TIBHannover/GeoEstimation/releases/download/v1.0/mp16_places365.csv -O resources/mp16_places365.csv\n",
        "wget https://github.com/TIBHannover/GeoEstimation/releases/download/pytorch/yfcc25600_places365.csv -O resources/yfcc25600_places365.csv\n",
        "python partitioning/assign_classes.py\n",
        "# remove images that were not downloaded \n",
        "python filter_by_downloaded_images.py\n",
        "\n",
        "# train geo model from scratch\n",
        "python -m classification.train_base --config config/baseM.yml\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2g9datY1blm",
        "outputId": "34433897-e9ea-495f-eaa8-54089db0e92f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "237\n",
            "/content/drive/MyDrive/GeoEstimation\n",
            "True\n",
            "1\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "os.chdir(r'/content/drive/MyDrive/GeoEstimation/resources/images/im2gps')\n",
        "print(len(os.listdir()))\n",
        "os.chdir(r'/content/drive/MyDrive/GeoEstimation')\n",
        "print(os.getcwd())\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Output would be True if Pytorch is using GPU otherwise it would be False.\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B3kpB3fnTzR",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#libraries to import\n",
        "#known\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import torchvision\n",
        "import torch\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import sys\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "\n",
        "#Unknown\n",
        "from typing import Union\n",
        "from io import BytesIO\n",
        "import random\n",
        "from argparse import Namespace, ArgumentParser\n",
        "from pathlib import Path\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "import requests\n",
        "import logging\n",
        "import json\n",
        "import yaml\n",
        "from tqdm.auto import tqdm\n",
        "#from classification.train_base import MultiPartitioningClassifier\n",
        "#from classification.dataset import FiveCropImageDataset\n",
        "\n",
        "#to divide\n",
        "from classification import utils_global\n",
        "from classification.s2_utils import Partitioning, Hierarchy\n",
        "from classification.dataset import MsgPackIterableDatasetMultiTargetWithDynLabels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFcvIDD5nTzr"
      },
      "source": [
        "The main link and paper that we need to follow is [this](https://github.com/TIBHannover/GeoEstimation) and [this](https://github.com/TIBHannover/GeoEstimation/releases/) for the pretrained models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56Y49vfnTzr"
      },
      "source": [
        "Davide ha trovato questo che forse è meglio [kaggle](https://www.kaggle.com/code/habedi/inspect-the-dataset/data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEsp9JRnTzs"
      },
      "source": [
        "[Qui](https://qualinet.github.io/databases/image/world_wide_scale_geotagged_image_dataset_for_automatic_image_annotation_and_reverse_geotagging/) ci sono dei links che potrebbero essere usati con colab col comando !wget."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "e583cc450fac4fd294c8076a1fbf5ede",
    "deepnote_persisted_session": {
      "createdAt": "2023-01-18T12:55:37.385Z"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fa9b9afc2baba5ccea1aafc34033c1dd8dcf2295c2dc2a369baeb32b0f17743"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
