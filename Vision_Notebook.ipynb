{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d112b5799924669bd63a025faac2662",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "Vision and Cognition System --- Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main link and paper that we need to follow is [this](https://github.com/TIBHannover/GeoEstimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we will need this [site](https://opensourceoptions.com/blog/use-python-to-download-multiple-files-or-urls-in-parallel/)\n",
    "\n",
    "Seguendo il paper [Where in the World is this Image? Transformer-based Geo-localization in the Wild](file:///C:/Users/latta/Downloads/Translocator_with_supplementary.pdf) tra le reference c'è il dataset del paper [Revisiting IM2GPS in the Deep Learning Era](https://arxiv.org/abs/1705.04838) che dà accesso al [sito](https://paperswithcode.com/dataset/yfcc100m) da cui si arriva in [Multimedia Commons](http://www.multimediacommons.org/). Qui comunque ci si rende conta che serve avere qualche tipo di account con i services di amazon per poter usare il dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4723695, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://farm1.staticflickr.com/91/236416609_d7daddff3b.jpg'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'f2/52/236416609.jpg'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(url['url'][10])\n",
    "display(url['name'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davide ha trovato questo che forse è meglio [kaggle](https://www.kaggle.com/code/habedi/inspect-the-dataset/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui ci sono dei links che potrebbero essere usati con colab col comando [!wget](https://qualinet.github.io/databases/image/world_wide_scale_geotagged_image_dataset_for_automatic_image_annotation_and_reverse_geotagging/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i**3)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e583cc450fac4fd294c8076a1fbf5ede",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-18T12:55:37.385Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
