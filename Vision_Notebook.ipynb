{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLeKGLqX_H4y"
   },
   "source": [
    "\n",
    "# Vision and Cognitive Systems - Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GianmarcoLattaruolo/Vision_Project/blob/main/Vision_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the working space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmXSsJJKniqF"
   },
   "source": [
    "In this first cell we check if the notebook is runnig in Colab. In this case we need some additional work to set properly the environmet. We need also to mount our vision drive. In local machine instead we need to add the Geoestimation folder of our paper in the paths where python searches for libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSi1dIDk_H5R",
    "outputId": "1dcf7ed1-5dba-48fb-ef6d-04ce4f4c7c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are we in Colab?: False\n"
     ]
    }
   ],
   "source": [
    "# with this line we can check if we are in colab or not\n",
    "import sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "print(\"are we in Colab?:\",in_colab)\n",
    "if in_colab:\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()\n",
    "else:\n",
    "    import os\n",
    "    current_wd = os.getcwd()\n",
    "    if current_wd.split('\\\\')[-1] == 'Vision_Project':\n",
    "        os.chdir(r'GeoEstimation')\n",
    "    sys.path.append(current_wd + r'\\GeoEstimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6EuxN1R_Zwi",
    "outputId": "eb15c5f6-6e31-4731-94ba-5be7a2f78a22"
   },
   "outputs": [],
   "source": [
    "# this cell takes a lot of time on colab!\n",
    "import sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "if in_colab:\n",
    "    import condacolab\n",
    "    condacolab.check()\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import os\n",
    "    os.chdir(r'/content/drive/MyDrive/GeoEstimation')\n",
    "    print(os.getcwd())\n",
    "    !conda env update -n base -f environment.yml\n",
    "    # The following is ridiculous, I know, but it seems to work\n",
    "    !pip uninstall torchtext\n",
    "    !pip install torchtext==0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSyJGMw23UYv"
   },
   "source": [
    "In theory we need to install some specific packages with certain version to account for the original environment in which the paper results were obtained:\n",
    "```\n",
    "  - python=3.8\n",
    "  - msgpack-python=1.0.0\n",
    "  - pandas=1.1.5\n",
    "  - yaml=0.2.5\n",
    "  - tqdm=4.50\n",
    "  - cudatoolkit=10.2\n",
    "  - pytorch=1.6\n",
    "  - torchvision=0.7\n",
    "  - pytorch-lightning=1.0.1\n",
    "  - pip\n",
    "  - pip:\n",
    "    - s2sphere==0.2.5\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells to download the new dataset\n",
    "Run this cell once you have the time download some images (set num_photo eventually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "#our defult working directory is Geoestimation\n",
    "\n",
    "def download_image(url, file_path, file_name, size = 'z'):\n",
    "    url = url[:-5]+size+url[-4:]\n",
    "    file_name = str(file_name)\n",
    "    full_path = file_path + '/'+ file_name + '.jpg'\n",
    "    try: \n",
    "        urllib.request.urlretrieve(url, full_path)\n",
    "        return 'ok'\n",
    "    except:\n",
    "        print(f'the url {url} does not work')\n",
    "        return ''\n",
    "\n",
    "\n",
    "def download_from_dataframe(df, num_photos=250):\n",
    "    os.chdir(r'/content/drive/MyDrive/GeoEstimation/resources/images/new_data10k')\n",
    "    cwd = os.getcwd()\n",
    "    count = 0\n",
    "    start = os.listdir()\n",
    "    if len(start)>10006:\n",
    "        print('Dataset already downloaded')\n",
    "        return\n",
    "    for i,url in enumerate(df['url']):\n",
    "        id = str(df['photo_id'][i])\n",
    "        \n",
    "        if id+'.jpg' not in start and count<num_photos and type(url)!=float:\n",
    "            status = download_image(url, cwd , id)\n",
    "            if status=='ok':\n",
    "                count += 1\n",
    "    #this is to return to the original parent folder\n",
    "    os.chdir(r'..')\n",
    "    os.chdir(r'..')\n",
    "    os.chdir(r'..')\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_data = pd.read_csv(r'/content/drive/MyDrive/GeoEstimation/resources/images/new_data10k/final_dataset.csv', sep = ';', index_col = 0)\n",
    "new_data.head(2)\n",
    "print('Previous number of Photos:',len(os.listdir(r'/content/drive/MyDrive/GeoEstimation/resources/images/new_data10k'))-1)\n",
    "download_from_dataframe(new_data)\n",
    "print('New number of Photos:',len(os.listdir(r'/content/drive/MyDrive/GeoEstimation/resources/images/new_data10k'))-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A transfer learning example: the strenght of pytorch-lightning\n",
    "\n",
    "Here we want to show in a nutshell the transfer learning approach from a pretrained model using both standard code and pytorch-lightning, to highlight the differences. Moreover we are going to load the same pretrained model (REsNet50) used by the authors as backbone to develop their ML model. For seek of semplicity we are going to re-train this model on the Cifar10. First let's see the classic torch approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you may need to install pytorch-lightning-bolts\n",
    "#!pip install pytorch-lightning-bolts==\n",
    "\n",
    "#libraries\n",
    "from torchvision import models\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import softmax, cross_entropy\n",
    "from torch.optim import Adam\n",
    "\n",
    "#download the pretrained model\n",
    "backbone = models.resnet50(pretrained = True)\n",
    "\n",
    "#download and normalize the CIFAR10 dataset\n",
    "normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "cf10_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "cifar_10 = CIFAR10('.',train=True, download = True, transform=cf10_transforms) \n",
    "\n",
    "\n",
    "#prepare the batches\n",
    "train_loader = DataLoader(cifar_10, batch_size=32, shuffle=True)\n",
    "\n",
    "# We add to the last layer with a fully connected one to match our number of classes (=10):\n",
    "# We treat the outputs of resnet as high level features (we could use them with any classifier instead of a FC)\n",
    "finetune_layer = torch.nn.Linear(backbone.fc.out_features, 10) \n",
    "#finetune_layer = torch.nn.Linear(backbone.fc.in_features, 10) is for REPLACE THE LAST LAYER\n",
    "\n",
    "#define the optimizer\n",
    "optimizer = Adam(finetune_layer.parameters(), lr = 1e-4)\n",
    "\n",
    "#training\n",
    "for epoch in range(10):\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        #we do not waste memory recording the gradient on the backbone\n",
    "        with torch.no_grad():\n",
    "            #(b, 3, 32, 32) -> (b, 1000)\n",
    "            features = backbone(x)\n",
    "\n",
    "        # (b, 1000) -> (b, 10)\n",
    "        preds = finetune_layer(features)\n",
    "        loss = cross_entropy(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(loss.item())\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10 , lr = 1e-3):\n",
    "        super().__init__()\n",
    "        #this setting save as the time to define an attribute for each hyperparameter --> self.hparams.<parameter>\n",
    "        self.save_hyperparameters() #Pytorch-lightning trick!\n",
    "        self.backbone = models.resnet50(pretrained = True)\n",
    "        self.finetune_layer = torch.nn.Linear(backbone.fc.out_features, num_classes)\n",
    "\n",
    "    def training_step(self, batch, batch_idx): #these methods are standard methods in LightningModule\n",
    "        x, y = batch\n",
    "\n",
    "        #we decide whether to freeze the backbone or not on the base of the number of epochs\n",
    "        if self.trainer.current_epoch < 10:\n",
    "            with torch.no_grad():\n",
    "                #(b, 3, 32, 32) -> (b, 1000)\n",
    "                features = self.backbone(x)\n",
    "        else:\n",
    "            features = self.backbone(x)\n",
    "\n",
    "        # (b, 1000) -> (b, 10)\n",
    "        preds = self.finetune_layer(features)\n",
    "        loss = cross_entropy(preds, y)\n",
    "        #we don't need anymore loss.backward(), optimizer.step(), optimizer.zero_grad()\n",
    "        self.log('train_loss', loss) # we will see later this method of LightningModule\n",
    "        self.log('train_loss', accuracy(preds, y))\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # (b, 1000) -> (b, 10)\n",
    "        preds = self.finetune_layer(features)\n",
    "        loss = cross_entropy(preds, y)\n",
    "        #we don't need anymore loss.backward(), optimizer.step(), optimizer.zero_grad()\n",
    "        self.log('val_loss', loss) # we will see later this method of LightningModule\n",
    "        self.log('val_loss', accuracy(preds, y))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr =self.hparams.lr) \n",
    "        #we can safely pass all the parameters since in the backbone we are not computing the gradient\n",
    "        return optimizer\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have  very handle object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "c:\\ProgramData\\Anaconda3\\envs\\vs-project\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:45: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name           | Type   | Params\n",
      "------------------------------------------\n",
      "0 | backbone       | ResNet | 25 M  \n",
      "1 | finetune_layer | Linear | 10 K  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80%|████████  | 40/50 [00:26<00:06,  1.48it/s, loss=2.094, v_num=0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pl_bolts.datamodules import CIFAR10DataModule\n",
    "\n",
    "#Bolts save us the time of train, vla, test split and using 3 different torch.Dataloader for each of them\n",
    "#dm = CIFAR10DataModule('.') \n",
    "\n",
    "classifier = ImageClassifier()\n",
    "logger = pl.loggers.TensorBoardLogger(name = f'pretrained model 1', save_dir = 'lightning_logs')\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = 2, # set the number of epochs if <1000 (=defult)\n",
    "    progress_bar_refresh_rate = 20, \n",
    "    logger = logger,\n",
    "    #gpus=1, \n",
    "    limit_train_batches = 50,\n",
    "    #limit_val_batches = 2,\n",
    "    #check_val_every_n_epoch = 5\n",
    "    #fast_dev_run=True # add this to have a fast chech of bugs\n",
    "    ) \n",
    "trainer.fit(classifier, train_loader)#dm) #we can use the normal train_loader we defined previously\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this very nice [tool](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.tensorboard.html#module-pytorch_lightning.loggers.tensorboard) form Pytorch-Lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-supervised transfer learning with Lightning\n",
    "\n",
    "PyTorch Lightning implementation of SwAV adapted from the [official implementation](https://arxiv.org/abs/2006.09882), whose authors used the same pretrained model (ResNet50 trained on ImageNet). We can simply import this model from Lightning-Bolt and define a class very similar to the previous one for our classifer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SwAV\n",
    "\n",
    "#weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/swav/bolts_swav_imagenet/swav_imagenet.ckpt'\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/swav/swav_imagenet/swav_imagenet.pth.tar'\n",
    "swav = SwAV.load_from_checkpoint(weight_path, strict=False)\n",
    "\n",
    "class SSLImageClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10 , lr = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() \n",
    "        self.backbone = swav.model #model pretrained on ImageNet without labels\n",
    "        self.finetune_layer = torch.nn.Linear(3000, num_classes)\n",
    "\n",
    "    def training_step(self, batch, batch_idx): #these methods are standard methods in \n",
    "        x, y = batch\n",
    "\n",
    "        #we decide whether to freeze the backbone or not on the base of the number of epochs\n",
    "        if self.trainer.current_epoch < 10:\n",
    "            with torch.no_grad():\n",
    "                #(b, 3, 32, 32) -> (b, 1000)\n",
    "                (f1, f2) = self.backbone(x)\n",
    "                features = f2\n",
    "        else:\n",
    "            (f1, f2) = self.backbone(x)\n",
    "            features = f2\n",
    "\n",
    "        # (b, 1000) -> (b, 10)\n",
    "        preds = self.finetune_layer(features)\n",
    "        loss = cross_entropy(preds, y)\n",
    "        #we don't need anymore loss.backward(), optimizer.step(), optimizer.zero_grad()\n",
    "        self.log('train_loss', loss) # we will see later this method of LightningModule\n",
    "        self.log('train_loss', accuracy(preds, y))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx): #these methods are standard methods in \n",
    "        x, y = batch\n",
    "        \n",
    "        (f1, f2) = self.backbone(x)\n",
    "        features = f2\n",
    "\n",
    "        # (b, 1000) -> (b, 10)\n",
    "        preds = self.finetune_layer(features)\n",
    "        loss = cross_entropy(preds, y)\n",
    "        #we don't need anymore loss.backward(), optimizer.step(), optimizer.zero_grad()\n",
    "        self.log('val_loss', loss) # we will see later this method of LightningModule\n",
    "        self.log('val_loss', accuracy(preds, y))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr =self.hparams.lr) \n",
    "        #we can safely pass all the parameters since in the backbone we are not computing the gradient\n",
    "        return optimizer\n",
    "        \n",
    "ssl_classifier = SSLImageClassifier()\n",
    "logger = pl.loggers.TensorBoardLogger(name = f'pretrained model 2 (self superised)', save_dir = 'lightning_logs')\n",
    "trainer = pl.Trainer(\n",
    "    # how to set the number of epochs?\n",
    "    progress_bar_refresh_rate = 20, \n",
    "    gpus=1, \n",
    "    limit_train_batches = 50#, \n",
    "    #fast_dev_run=True # add this to have a fast chech of bugs\n",
    "    ) \n",
    "trainer.fit(classifier, dm) #we can use the normal train_loader we defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R4BF4QseoP35"
   },
   "source": [
    "## Reproduce paper results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwz47JYx_H5b"
   },
   "source": [
    "To begin we try to reproduce the paper results on their test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ay_jd1lT_H5d"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from classification.train_base import MultiPartitioningClassifier # class defining our model\n",
    "from classification.dataset import FiveCropImageDataset # class for preparing the images before giving them to the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiYqpWSn_H5i"
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9s09ZTd3_H5k"
   },
   "outputs": [],
   "source": [
    "# where model's params and hyperparams are saved\n",
    "checkpoint = \"models/base_M/epoch=014-val_loss=18.4833.ckpt\"\n",
    "hparams = \"models/base_M/hparams.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "1d2f7216c09848f7b62dd370f593a504",
      "ba23302efe764485bba72edf0cbee901",
      "5c60e3f5df3f475d9b2c6cabc23cd1ee",
      "712784300bc9405da3a49e8fb67e6f5f",
      "8ae9d1ee6f0d4954bce1015d70b73f13",
      "1c20d473ae664b86a410214a5eece69f",
      "3d04bbb6e26b4085a8a4611452142188",
      "aa1818d91cda41908b16dd7d013717f4",
      "0e61292ae7af4aca9aa2f0ae63fcd3ed",
      "71031674ab374cdf8afdace7ca303650",
      "ed127fb12a094fd6acf61eb176daef10"
     ]
    },
    "id": "2IsHtRs6_H5m",
    "outputId": "fd184891-6dac-4084-db68-49196d657c07"
   },
   "outputs": [],
   "source": [
    "# load_from_checkpoint is a static method from pytorch lightning, inherited by MultiPartitioningClassifier\n",
    "# it permits to load a model previously saved, in the form of a checkpoint file, and one with hyperparameters\n",
    "# MultiPartitioningClassifier is the class defining our model\n",
    "model = MultiPartitioningClassifier.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint,\n",
    "    hparams_file=hparams,\n",
    "    map_location=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abc.ABCMeta"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pl.LightningModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lANl7PDx_H5o",
    "outputId": "7501e096-091e-4cc5-b43d-1412a4ce825a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "#to allow GPU\n",
    "want_gpu = True\n",
    "if want_gpu and torch.cuda.is_available():\n",
    "    gpu = 1\n",
    "else:\n",
    "    gpu = None\n",
    "\n",
    "# the class Trainer from pythorch lightining is the one responsible for training a deep NN\n",
    "# it can initialize the model, run forward and backward passes, optimize, print stats, early stop...\n",
    "wanted_precision = 32 #16 for half precision (how many bits for each number)\n",
    "trainer = pl.Trainer(gpus=gpu, precision=wanted_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csYOzf4r_H5p"
   },
   "source": [
    "## Load and initialize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FdLRVDHC_H5q"
   },
   "outputs": [],
   "source": [
    "# where images are saved\n",
    "image_dir = \"resources/images/im2gps\"\n",
    "meta_csv = \"resources/images/im2gps_places365.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "first_csv = pd.read_csv(meta_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nf0Rm1h8_H5r",
    "outputId": "04d72f0d-4300-49a2-a47b-46838ed94463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read resources/images/im2gps_places365.csv\n"
     ]
    }
   ],
   "source": [
    "#FiveCropImageDataset is the class for preparing the images before giving them to the NN\n",
    "# in particular, it creates five different crops for every image\n",
    "dataset = FiveCropImageDataset(meta_csv, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JNIX_tu2_H5s"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=ceil(batch_size / 5),  #you divide by 5 because for each image you generate 5 different crops\n",
    "                    shuffle=False,\n",
    "                    num_workers=4 #number ot threads used for parallelism (cores of CPU?)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQycvZEH_H5s"
   },
   "source": [
    "## Run the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "764b8115188b4b2284e17d22e3558b2a",
      "cc08b974516c4d4397d9e221056c5439",
      "8f0110a480174fc5ac1dcf4d932740f9",
      "72ba8a7b26f14efc8025fa99f41b3969",
      "1915b60a52be4226a3a1673a3820d500",
      "c36b3c562cbb4eb29f7d3751c20ab878",
      "20e5622c71eb4b9db4046ae20267252d",
      "b2e09264f96e45389781824a6c9831ba",
      "5245c9ed1c0246579b14794c62669e88",
      "3b107de858db418c9132702a5a287aca",
      "a7801836fe2440429f2ff28e419b6192"
     ]
    },
    "id": "gwfspFbj_H5t",
    "outputId": "044953bc-80bc-4f29-c6ae-3e8ac61db70e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764b8115188b4b2284e17d22e3558b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The testing_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test(model, test_dataloaders=dataloader, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu5nzy7B_H5u"
   },
   "source": [
    "## Look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OHtm_1M_H5u",
    "outputId": "ddcd9360-8c36-454c-8ef5-c71bcbd32296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  1         25        200       750       2500\n",
      "partitioning                                                  \n",
      "coarse        0.092827  0.316456  0.497890  0.670886  0.789030\n",
      "middle        0.139241  0.345992  0.481013  0.683544  0.793249\n",
      "fine          0.156118  0.392405  0.489451  0.658228  0.784810\n",
      "hierarchy     0.147679  0.375527  0.489451  0.683544  0.789030\n"
     ]
    }
   ],
   "source": [
    "# formatting results into a pandas dataframe\n",
    "df = pd.DataFrame(results[0]).T\n",
    "#df[\"dataset\"] = image_dir\n",
    "df[\"partitioning\"] = df.index\n",
    "df[\"partitioning\"] = df[\"partitioning\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "df.set_index(keys=[\"partitioning\"], inplace=True) #keys=[\"dataset\", \"partitioning\"] in case\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6vSJgR0_H5v"
   },
   "outputs": [],
   "source": [
    "# to save the dataframe on a csv file\n",
    "fout = 'test_results.csv'\n",
    "df.to_csv(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2g9datY1blm",
    "outputId": "34433897-e9ea-495f-eaa8-54089db0e92f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "/content/drive/MyDrive/GeoEstimation\n",
      "True\n",
      "1\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'/content/drive/MyDrive/GeoEstimation/resources/images/im2gps')\n",
    "print(len(os.listdir()))\n",
    "os.chdir(r'/content/drive/MyDrive/GeoEstimation')\n",
    "print(os.getcwd())\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Output would be True if Pytorch is using GPU otherwise it would be False.\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_B3kpB3fnTzR",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#libraries to import\n",
    "#known\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import torchvision\n",
    "import torch\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import sys\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "\n",
    "#Unknown\n",
    "from typing import Union\n",
    "from io import BytesIO\n",
    "import random\n",
    "from argparse import Namespace, ArgumentParser\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import requests\n",
    "import logging\n",
    "import json\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "#from classification.train_base import MultiPartitioningClassifier\n",
    "#from classification.dataset import FiveCropImageDataset\n",
    "\n",
    "#to divide\n",
    "from classification import utils_global\n",
    "from classification.s2_utils import Partitioning, Hierarchy\n",
    "from classification.dataset import MsgPackIterableDatasetMultiTargetWithDynLabels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFcvIDD5nTzr"
   },
   "source": [
    "The main link and paper that we need to follow is [this](https://github.com/TIBHannover/GeoEstimation) and [this](https://github.com/TIBHannover/GeoEstimation/releases/) for the pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e56Y49vfnTzr"
   },
   "source": [
    "Davide ha trovato questo che forse è meglio [kaggle](https://www.kaggle.com/code/habedi/inspect-the-dataset/data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e583cc450fac4fd294c8076a1fbf5ede",
  "deepnote_persisted_session": {
   "createdAt": "2023-01-18T12:55:37.385Z"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fa9b9afc2baba5ccea1aafc34033c1dd8dcf2295c2dc2a369baeb32b0f17743"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e61292ae7af4aca9aa2f0ae63fcd3ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1915b60a52be4226a3a1673a3820d500": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "1c20d473ae664b86a410214a5eece69f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d2f7216c09848f7b62dd370f593a504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba23302efe764485bba72edf0cbee901",
       "IPY_MODEL_5c60e3f5df3f475d9b2c6cabc23cd1ee",
       "IPY_MODEL_712784300bc9405da3a49e8fb67e6f5f"
      ],
      "layout": "IPY_MODEL_8ae9d1ee6f0d4954bce1015d70b73f13"
     }
    },
    "20e5622c71eb4b9db4046ae20267252d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b107de858db418c9132702a5a287aca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d04bbb6e26b4085a8a4611452142188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5245c9ed1c0246579b14794c62669e88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c60e3f5df3f475d9b2c6cabc23cd1ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa1818d91cda41908b16dd7d013717f4",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e61292ae7af4aca9aa2f0ae63fcd3ed",
      "value": 102502400
     }
    },
    "71031674ab374cdf8afdace7ca303650": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "712784300bc9405da3a49e8fb67e6f5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71031674ab374cdf8afdace7ca303650",
      "placeholder": "​",
      "style": "IPY_MODEL_ed127fb12a094fd6acf61eb176daef10",
      "value": " 97.8M/97.8M [00:34&lt;00:00, 2.97MB/s]"
     }
    },
    "72ba8a7b26f14efc8025fa99f41b3969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b107de858db418c9132702a5a287aca",
      "placeholder": "​",
      "style": "IPY_MODEL_a7801836fe2440429f2ff28e419b6192",
      "value": " 19/19 [00:20&lt;00:00,  1.10s/it]"
     }
    },
    "764b8115188b4b2284e17d22e3558b2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc08b974516c4d4397d9e221056c5439",
       "IPY_MODEL_8f0110a480174fc5ac1dcf4d932740f9",
       "IPY_MODEL_72ba8a7b26f14efc8025fa99f41b3969"
      ],
      "layout": "IPY_MODEL_1915b60a52be4226a3a1673a3820d500"
     }
    },
    "8ae9d1ee6f0d4954bce1015d70b73f13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f0110a480174fc5ac1dcf4d932740f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2e09264f96e45389781824a6c9831ba",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5245c9ed1c0246579b14794c62669e88",
      "value": 1
     }
    },
    "a7801836fe2440429f2ff28e419b6192": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa1818d91cda41908b16dd7d013717f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2e09264f96e45389781824a6c9831ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba23302efe764485bba72edf0cbee901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c20d473ae664b86a410214a5eece69f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d04bbb6e26b4085a8a4611452142188",
      "value": "100%"
     }
    },
    "c36b3c562cbb4eb29f7d3751c20ab878": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc08b974516c4d4397d9e221056c5439": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c36b3c562cbb4eb29f7d3751c20ab878",
      "placeholder": "​",
      "style": "IPY_MODEL_20e5622c71eb4b9db4046ae20267252d",
      "value": "Testing: 100%"
     }
    },
    "ed127fb12a094fd6acf61eb176daef10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
